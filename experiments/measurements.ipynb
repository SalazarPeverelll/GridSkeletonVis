{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temporal ranking corr and fixing moving invariants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import argparse\n",
    "import numpy as np\n",
    "import json\n",
    "\n",
    "from umap.umap_ import find_ab_params\n",
    "sys.path.append(\"..\")\n",
    "from singleVis.SingleVisualizationModel import SingleVisualizationModel\n",
    "from singleVis.data import NormalDataProvider\n",
    "from singleVis.eval.evaluator import Evaluator\n",
    "from singleVis.projector import TimeVisProjector\n",
    "from singleVis.SingleVisualizationModel import VisModel\n",
    "from singleVis.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VIS_METHOD = \"TimeVis\" # DeepVisualInsight\n",
    "CONTENT_PATH = \"/home/xianglin/projects/DVI_data/resnet18_fmnist\"\n",
    "GPU_ID = \"3\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(CONTENT_PATH)\n",
    "with open(os.path.join(CONTENT_PATH, \"config.json\"), \"r\") as f:\n",
    "    config = json.load(f)\n",
    "config = config[VIS_METHOD]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SETTING = config[\"SETTING\"]\n",
    "CLASSES = config[\"CLASSES\"]\n",
    "DATASET = config[\"DATASET\"]\n",
    "PREPROCESS = config[\"VISUALIZATION\"][\"PREPROCESS\"]\n",
    "\n",
    "# Training parameter (subject model)\n",
    "TRAINING_PARAMETER = config[\"TRAINING\"]\n",
    "NET = TRAINING_PARAMETER[\"NET\"]\n",
    "LEN = TRAINING_PARAMETER[\"train_num\"]\n",
    "EPOCH_START = config[\"EPOCH_START\"]\n",
    "EPOCH_END = config[\"EPOCH_END\"]\n",
    "EPOCH_PERIOD = config[\"EPOCH_PERIOD\"]\n",
    "\n",
    "# Training parameter (visualization model)\n",
    "VISUALIZATION_PARAMETER = config[\"VISUALIZATION\"]\n",
    "B_N_EPOCHS = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"B_N_EPOCHS\"]\n",
    "L_BOUND = VISUALIZATION_PARAMETER[\"BOUNDARY\"][\"L_BOUND\"]\n",
    "ENCODER_DIMS = VISUALIZATION_PARAMETER[\"ENCODER_DIMS\"]\n",
    "DECODER_DIMS = VISUALIZATION_PARAMETER[\"DECODER_DIMS\"]\n",
    "S_N_EPOCHS = VISUALIZATION_PARAMETER[\"S_N_EPOCHS\"]\n",
    "N_NEIGHBORS = VISUALIZATION_PARAMETER[\"N_NEIGHBORS\"]\n",
    "PATIENT = VISUALIZATION_PARAMETER[\"PATIENT\"]\n",
    "MAX_EPOCH = VISUALIZATION_PARAMETER[\"MAX_EPOCH\"]\n",
    "\n",
    "VIS_MODEL_NAME = VISUALIZATION_PARAMETER[\"VIS_MODEL_NAME\"]\n",
    "EVALUATION_NAME = VISUALIZATION_PARAMETER[\"EVALUATION_NAME\"]\n",
    "\n",
    "# Define hyperparameters\n",
    "DEVICE = torch.device(\"cuda:{}\".format(GPU_ID) if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import Model.model as subject_model\n",
    "net = eval(\"subject_model.{}()\".format(NET))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_provider = NormalDataProvider(CONTENT_PATH, net, EPOCH_START, EPOCH_END, EPOCH_PERIOD, device=DEVICE, classes=CLASSES, epoch_name=\"Epoch\", verbose=1)\n",
    "if PREPROCESS:\n",
    "    data_provider._meta_data()\n",
    "    if B_N_EPOCHS >0:\n",
    "        data_provider._estimate_boundary(LEN//10, l_bound=L_BOUND)\n",
    "\n",
    "\n",
    "model = VisModel(ENCODER_DIMS, DECODER_DIMS)\n",
    "projector = TimeVisProjector(vis_model=model, content_path=CONTENT_PATH, vis_model_name=VIS_MODEL_NAME, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator = Evaluator(data_provider, projector)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for s,e in [(1,25),(25,50),(1,50),(1,5),(23,27),(46,50)]:\n",
    "    evaluator.eval_moving_invariants_train(s,e)\n",
    "    evaluator.eval_moving_invariants_test(s,e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluator.eval_proj_invariants_train(180)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# temporal nn spearman ranking test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_dist(a,b):  \n",
    "    n = len(a)\n",
    "    assert len(b) == n\n",
    "    i, j = np.meshgrid(np.arange(n), np.arange(n))\n",
    "    ndisordered = np.logical_or(np.logical_and(a[i] < a[j], b[i] > b[j]), np.logical_and(a[i] > a[j], b[i] < b[j])).sum()\n",
    "    return ndisordered / (n * (n - 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_change(all_train_repr, low_repr, e_s, e_e, l):\n",
    "    correct = 0\n",
    "    pool = 0\n",
    "    for idx in range(l):\n",
    "        high_embeddings = all_train_repr[:,idx,:]\n",
    "        low_embeddings = low_repr[:,idx,:]\n",
    "        high_rank_s = np.argsort(np.linalg.norm(high_embeddings - high_embeddings[e_s-1], axis=1))\n",
    "        high_rank_e = np.argsort(np.linalg.norm(high_embeddings - high_embeddings[e_e-1], axis=1))\n",
    "        dist = ranking_dist(high_rank_s, high_rank_e)\n",
    "        if dist >0.5:\n",
    "            pool += 1\n",
    "            low_rank_s = np.argsort(np.linalg.norm(low_embeddings - low_embeddings[e_s-1], axis=1))\n",
    "            low_rank_e = np.argsort(np.linalg.norm(low_embeddings - low_embeddings[e_e-1], axis=1))\n",
    "            low_dist = ranking_dist(low_rank_s, low_rank_e)\n",
    "            if low_dist>0.5:\n",
    "                correct+=1\n",
    "    print(f'Radical Change in Low/High:\\t{correct}/{pool}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = 200\n",
    "LEN = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_train_repr = np.zeros((EPOCH,LEN,512))\n",
    "for i in range(1,201,1):\n",
    "    all_train_repr[i-1] = data_provider.train_representation(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "low_repr = np.zeros((EPOCH,LEN,2))\n",
    "for e in range(EPOCH):\n",
    "    low_repr[e] = projector.batch_project(e+1, all_train_repr[e])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ranking_change(all_train_repr, low_repr, 100,150, LEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shape (200, 50000, 512)\n",
    "epochs = [i for i in range(EPOCH)]\n",
    "corrs = np.zeros((EPOCH,500))\n",
    "ps = np.zeros((EPOCH,500))\n",
    "for i in range(500):\n",
    "    high_embeddings = all_train_repr[:,i,:].squeeze()\n",
    "    low_embeddings = low_repr[:,i,:].squeeze()\n",
    "\n",
    "    for e in epochs:\n",
    "        high_dists = np.linalg.norm(high_embeddings - high_embeddings[e], axis=1)\n",
    "        low_dists = np.linalg.norm(low_embeddings - low_embeddings[e], axis=1)\n",
    "        corr, p = stats.spearmanr(high_dists, low_dists)\n",
    "        corrs[e][i] = corr\n",
    "        ps[e][i] = p\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mean_corr = np.mean(corrs, axis=1)\n",
    "var_corr = np.var(corrs, axis=1)\n",
    "\n",
    "mean_p = np.mean(ps, axis=1)\n",
    "var_p = np.var(ps, axis=1)\n",
    "\n",
    "\n",
    "p1 = plt.plot(epochs, mean_corr, \"b.-\", epochs, mean_p, \"r+-\")\n",
    "p2 = plt.fill_between(epochs, mean_corr-var_corr, mean_corr+var_corr)\n",
    "p3 = plt.fill_between(epochs, mean_p-var_p, mean_p+var_p)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mean_corr = np.mean(corrs, axis=1)\n",
    "var_corr = np.var(corrs, axis=1)\n",
    "\n",
    "mean_p = np.mean(ps, axis=1)\n",
    "var_p = np.var(ps, axis=1)\n",
    "\n",
    "\n",
    "p1 = plt.plot(epochs, mean_corr, \"b.-\", epochs, mean_p, \"r+-\")\n",
    "p2 = plt.fill_between(epochs, mean_corr-var_corr, mean_corr+var_corr)\n",
    "p3 = plt.fill_between(epochs, mean_p-var_p, mean_p+var_p)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "mean_corr = np.mean(corrs, axis=1)\n",
    "var_corr = np.var(corrs, axis=1)\n",
    "\n",
    "mean_p = np.mean(ps, axis=1)\n",
    "var_p = np.var(ps, axis=1)\n",
    "\n",
    "\n",
    "p1 = plt.plot(epochs, mean_corr, \"b-\", epochs, mean_p, \"r-\")\n",
    "p2 = plt.fill_between(epochs, mean_corr-var_corr, mean_corr+var_corr)\n",
    "p3 = plt.fill_between(epochs, mean_p-var_p, mean_p+var_p)\n",
    "plt.show"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fixing invarient and Moving invarient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import softmax\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_s = 2\n",
    "e_t = 40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_s = data_provider.train_representation(e_s)\n",
    "train_data_t = data_provider.train_representation(e_t)\n",
    "pred_s = data_provider.get_pred(e_s, train_data_s)\n",
    "pred_t = data_provider.get_pred(e_t, train_data_t)\n",
    "\n",
    "labels = data_provider.train_labels(20)\n",
    "\n",
    "model = trainer.model\n",
    "\n",
    "low_s = model.encoder(torch.from_numpy(train_data_s).to(device=DEVICE).float()).detach().cpu().numpy()\n",
    "low_t = model.encoder(torch.from_numpy(train_data_t).to(device=DEVICE).float()).detach().cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## correlation between (kl div/js div/loss) and dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_div(p, q):\n",
    "    return stats.entropy(p, q, base=2)\n",
    "\n",
    "\n",
    "def js_div(p, q):\n",
    "    M = (p+q)/2\n",
    "    return .5*kl_div(p, M)+.5*kl_div(q, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kl\n",
    "softmax_s = softmax(pred_s, axis=1)\n",
    "softmax_t = softmax(pred_t, axis=1)\n",
    "kl_lists = [kl_div(softmax_s[i], softmax_t[i]) for i in range(len(softmax_t))]\n",
    "dists = [cosine(low_t[i], low_s[i]) for i in range(len(low_s))]\n",
    "corr, p = stats.spearmanr(kl_lists, dists)\n",
    "corr, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# js\n",
    "js_lists = [js_div(softmax_s[i], softmax_t[i]) for i in range(len(softmax_t))]\n",
    "dists = [cosine(low_t[i], low_s[i]) for i in range(len(low_s))]\n",
    "corr, p = stats.spearmanr(js_lists, dists)\n",
    "corr, p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss\n",
    "loss_s = softmax_s[range(LEN), labels]\n",
    "loss_t = softmax_t[range(LEN), labels]\n",
    "loss_diff = np.abs(loss_s-loss_t)\n",
    "\n",
    "dists = [cosine(low_t[i], low_s[i]) for i in range(len(low_s))]\n",
    "corr, p = stats.spearmanr(js_lists, dists)\n",
    "corr, p"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fixing and moving comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize low dimension distance\n",
    "mean_x = np.mean(low_t[:, 0])\n",
    "mean_y = np.mean(low_t[:, 1])\n",
    "low_t = low_t - [mean_x, mean_y]\n",
    "low_s = low_s - [mean_x, mean_y]\n",
    "\n",
    "max_n = np.linalg.norm(low_t)\n",
    "low_t = low_t/max_n*100\n",
    "low_s = low_s/max_n*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.linalg.norm((train_data_s-train_data_t),axis=1).mean(), np.linalg.norm((low_s-low_t),axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = np.argsort(kl_lists)\n",
    "print(\"kl div\")\n",
    "print(\"fixing\\t\", np.linalg.norm((train_data_s-train_data_t)[selected[:100]],axis=1).mean(), np.linalg.norm((low_s-low_t)[selected[:100]],axis=1).mean())\n",
    "print(\"moving\\t\", np.linalg.norm((train_data_s-train_data_t)[selected[-100:]],axis=1).mean(), np.linalg.norm((low_s-low_t)[selected[-100:]],axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = np.argsort(js_lists)\n",
    "print(\"js div\")\n",
    "print(\"fixing\\t\", np.linalg.norm((train_data_s-train_data_t)[selected[:100]],axis=1).mean(), np.linalg.norm((low_s-low_t)[selected[:100]],axis=1).mean())\n",
    "print(\"moving\\t\", np.linalg.norm((train_data_s-train_data_t)[selected[-100:]],axis=1).mean(), np.linalg.norm((low_s-low_t)[selected[-100:]],axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected = np.argsort(loss_diff)\n",
    "print(\"loss diff\")\n",
    "print(\"fixing\\t\", np.linalg.norm((train_data_s-train_data_t)[selected[:100]],axis=1).mean(), np.linalg.norm((low_s-low_t)[selected[:100]],axis=1).mean())\n",
    "print(\"moving\\t\", np.linalg.norm((train_data_s-train_data_t)[selected[-100:]],axis=1).mean(), np.linalg.norm((low_s-low_t)[selected[-100:]],axis=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## inside(outside)-class moving dists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_s = pred_s.argmax(axis=1)\n",
    "p_t = pred_t.argmax(axis=1)\n",
    "for i in range(10):\n",
    "    selected = np.logical_and(p_s==i, p_s==p_t)\n",
    "    print(i, np.linalg.norm((train_data_s-train_data_t)[selected],axis=1).mean(), np.linalg.norm((low_s-low_t)[selected],axis=1).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    selected = np.logical_and(p_s==i, p_s!=p_t)\n",
    "    print(i, np.linalg.norm((train_data_s-train_data_t)[selected],axis=1).mean(), np.linalg.norm((low_s-low_t)[selected],axis=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## npr and prediction based measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.backend import find_neighbor_preserving_rate\n",
    "\n",
    "npr = find_neighbor_preserving_rate(train_data_s, train_data_t, 15)\n",
    "selected_fix = np.logical_and(npr>0.1, p_s==p_t)\n",
    "for i in range(10):\n",
    "    selected = np.logical_and(selected_fix, p_s==i)\n",
    "    print(i, np.linalg.norm((train_data_s-train_data_t)[selected],axis=1).mean(), np.linalg.norm((low_s-low_t)[selected],axis=1).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fixing and moving invariants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## moving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_s = 1\n",
    "e_t = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_s = data_provider.train_representation(e_s)\n",
    "train_data_t = data_provider.train_representation(e_t)\n",
    "pred_s = data_provider.get_pred(e_s, train_data_s)\n",
    "pred_t = data_provider.get_pred(e_t, train_data_t)\n",
    "\n",
    "labels = data_provider.train_labels(20)\n",
    "\n",
    "model = trainer.model\n",
    "\n",
    "low_s = model.encoder(torch.from_numpy(train_data_s).to(device=DEVICE).float()).detach().cpu().numpy()\n",
    "low_t = model.encoder(torch.from_numpy(train_data_t).to(device=DEVICE).float()).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.utils import is_B\n",
    "s_B = is_B(pred_s)\n",
    "t_B = is_B(pred_t)\n",
    "\n",
    "predictions_s = pred_s.argmax(1)\n",
    "predictions_t = pred_t.argmax(1)\n",
    "\n",
    "confident_sample = np.logical_and(np.logical_not(s_B),np.logical_not(t_B))\n",
    "diff_pred = predictions_s!=predictions_t\n",
    "\n",
    "selected = np.logical_and(diff_pred, confident_sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from singleVis.visualizer import visualizer\n",
    "resolution = 500\n",
    "vis = visualizer(data_provider, trainer.model, resolution, 10, classes, cmap='tab10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_view_s, decision_view_s = vis.get_epoch_decision_view(e_s, resolution)\n",
    "grid_view_t, decision_view_t = vis.get_epoch_decision_view(e_t, resolution)\n",
    "\n",
    "grid_view_s = grid_view_s.reshape(resolution*resolution, -1)\n",
    "grid_view_t = grid_view_t.reshape(resolution*resolution, -1)\n",
    "\n",
    "grid_samples_s = trainer.model.decoder(grid_view_s).cpu().detach().numpy()\n",
    "grid_samples_t = trainer.model.decoder(grid_view_t).cpu().detach().numpy()\n",
    "\n",
    "grid_pred_s = data_provider.get_pred(e_s, grid_samples_s)+1e-8\n",
    "grid_pred_t = data_provider.get_pred(e_t, grid_samples_t)+1e-8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_view_s = grid_view_s.cpu().detach().numpy()\n",
    "grid_view_t = grid_view_t.cpu().detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_s_B = is_B(grid_pred_s)\n",
    "grid_t_B = is_B(grid_pred_t)\n",
    "\n",
    "grid_predictions_s = grid_pred_s.argmax(1)\n",
    "grid_predictions_t = grid_pred_t.argmax(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_neigh = NearestNeighbors(n_neighbors=1, radius=0.4)\n",
    "high_neigh.fit(grid_view_s)\n",
    "knn_dists, knn_indices = high_neigh.kneighbors(low_s, n_neighbors=1, return_distance=True)\n",
    "\n",
    "close_s_pred = grid_predictions_s[knn_indices].squeeze()\n",
    "close_s_B = grid_s_B[knn_indices].squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_true = np.logical_and(close_s_pred==predictions_s, close_s_B == s_B)\n",
    "np.sum(s_true[selected]), np.sum(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_neigh = NearestNeighbors(n_neighbors=1, radius=0.4)\n",
    "high_neigh.fit(grid_view_t)\n",
    "knn_dists, knn_indices = high_neigh.kneighbors(low_t, n_neighbors=1, return_distance=True)\n",
    "\n",
    "close_t_pred = grid_predictions_t[knn_indices].squeeze()\n",
    "close_t_B = grid_t_B[knn_indices].squeeze()\n",
    "np.sum(grid_t_B), np.sum(t_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_true = np.logical_and(close_t_pred==predictions_t, close_t_B == t_B)\n",
    "np.sum(t_true[selected]), np.sum(selected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(np.logical_and(s_true[selected], t_true[selected])), np.sum(selected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fixing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fixing invariants\n",
    "from scipy.special import softmax\n",
    "from scipy import stats\n",
    "from scipy.spatial.distance import cosine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kl_div(p, q):\n",
    "    return stats.entropy(p, q, base=2)\n",
    "\n",
    "\n",
    "def js_div(p, q):\n",
    "    M = (p+q)/2\n",
    "    return .5*kl_div(p, M)+.5*kl_div(q, M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_s = 1\n",
    "e_t = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_s = data_provider.train_representation(e_s)\n",
    "train_data_t = data_provider.train_representation(e_t)\n",
    "pred_s = data_provider.get_pred(e_s, train_data_s)\n",
    "pred_t = data_provider.get_pred(e_t, train_data_t)\n",
    "softmax_s = softmax(pred_s, axis=1)\n",
    "softmax_t = softmax(pred_t, axis=1)\n",
    "\n",
    "labels = data_provider.train_labels(20)\n",
    "\n",
    "model = trainer.model\n",
    "\n",
    "low_s = model.encoder(torch.from_numpy(train_data_s).to(device=DEVICE).float()).detach().cpu().numpy()\n",
    "low_t = model.encoder(torch.from_numpy(train_data_t).to(device=DEVICE).float()).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalize low_t\n",
    "y_max = max(low_s[:, 1].max(), low_t[:, 1].max())\n",
    "y_min = max(low_s[:, 1].min(), low_t[:, 1].min())\n",
    "x_max = max(low_s[:, 0].max(), low_t[:, 0].max())\n",
    "x_min = max(low_s[:, 0].min(), low_t[:, 0].min())\n",
    "scale = min(100/(x_max - x_min), 100/(y_max - y_min))\n",
    "low_t = low_t*scale\n",
    "low_s = low_s*scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "high_dists = np.linalg.norm(train_data_s-train_data_t, axis=1)\n",
    "softmax_dists = np.array([js_div(softmax_s[i], softmax_t[i]) for i in range(len(softmax_t))])\n",
    "euclidean_dists = np.linalg.norm(low_s-low_t, axis=1)\n",
    "# cosine_dists = np.array([cosine(low_t[i], low_s[i]) for i in range(len(low_s))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the minimum distance\n",
    "from pynndescent import NNDescent\n",
    "# number of trees in random projection forest\n",
    "n_trees = min(64, 5 + int(round((train_data_t.shape[0]) ** 0.5 / 20.0)))\n",
    "# max number of nearest neighbor iters to perform\n",
    "n_iters = max(5, int(round(np.log2(train_data_t.shape[0]))))\n",
    "# distance metric\n",
    "metric = \"euclidean\"\n",
    "# metric = \"cosine\"\n",
    "# get nearest neighbors\n",
    "\n",
    "nnd = NNDescent(\n",
    "    train_data_t,\n",
    "    n_neighbors=2,\n",
    "    metric=metric,\n",
    "    n_trees=n_trees,\n",
    "    n_iters=n_iters,\n",
    "    max_candidates=60,\n",
    "    verbose=False\n",
    ")\n",
    "knn_indices, knn_dists = nnd.neighbor_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_ind = knn_dists[:, 1]\n",
    "nn_dists = knn_dists[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = nn_dists.max()\n",
    "threshold = 0.5\n",
    "if np.sum(selected) == 0:\n",
    "    print(\"No fixing points!\")\n",
    "else:\n",
    "    print(\"euclidean dists\")\n",
    "    print(np.sum(euclidean_dists[selected]<low_threshold), np.sum(selected))\n",
    "    print(euclidean_dists[selected].min(), euclidean_dists.min())\n",
    "    print(euclidean_dists[selected].mean(), euclidean_dists.mean())\n",
    "    print(euclidean_dists[selected].max(), euclidean_dists.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "softmax_diff = np.array([js_div(softmax_s[i], softmax_s[j]) for (i,j) in knn_indices])\n",
    "threshold = softmax_diff.max()\n",
    "selected = softmax_dists<=threshold\n",
    "if np.sum(selected) == 0:\n",
    "    print(\"No fixing points!\")\n",
    "else:\n",
    "# selected = np.argsort(high_dists)[:100]\n",
    "    print(\"euclidean dists\")\n",
    "    print(euclidean_dists[selected].min(), euclidean_dists.min())\n",
    "    print(euclidean_dists[selected].mean(), euclidean_dists.mean())\n",
    "    print(euclidean_dists[selected].max(), euclidean_dists.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph mutual information\n",
    "**node and features**\n",
    "- topology\n",
    "- mutual information\n",
    ">>\n",
    "intrinsic dimension\n",
    "softmax kl div"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "aa7a9f36e1a1e240450dbe9cc8f6d8df1d5301f36681fb271c44fdd883236b60"
  },
  "kernelspec": {
   "display_name": "Python 3.7.11 ('SV': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
